{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Application III: Comparing Classifiers\n",
    "\n",
    "**Overview**: In this practical application, your goal is to compare the performance of the classifiers we encountered in this section, namely K Nearest Neighbor, Logistic Regression, Decision Trees, and Support Vector Machines.  We will utilize a dataset related to marketing bank products over the telephone.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Started\n",
    "\n",
    "Our dataset comes from the UCI Machine Learning repository [link](https://archive.ics.uci.edu/ml/datasets/bank+marketing).  The data is from a Portugese banking institution and is a collection of the results of multiple marketing campaigns.  We will make use of the article accompanying the dataset [here](CRISP-DM-BANK.pdf) for more information on the data and features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1: Understanding the Data\n",
    "\n",
    "To gain a better understanding of the data, please read the information provided in the UCI link above, and examine the **Materials and Methods** section of the paper.  How many marketing campaigns does this data represent?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data represents 17 marketing campaigns occured between May 2008 and Nov 2010, corresponding to a total of 79354 contacts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2: Read in the Data\n",
    "\n",
    "Use pandas to read in the dataset `bank-additional-full.csv` and assign to a meaningful variable name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook\"\n",
    "import time\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import  accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collect Initial Data\n",
    "df = pd.read_csv('../data/bank-additional-full.csv', sep = ';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3: Understanding the Features\n",
    "\n",
    "\n",
    "Examine the data description below, and determine if any of the features are missing values or need to be coerced to a different data type.\n",
    "\n",
    "\n",
    "```\n",
    "Input variables:\n",
    "# bank client data:\n",
    "1 - age (numeric)\n",
    "2 - job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n",
    "3 - marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n",
    "4 - education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n",
    "5 - default: has credit in default? (categorical: 'no','yes','unknown')\n",
    "6 - housing: has housing loan? (categorical: 'no','yes','unknown')\n",
    "7 - loan: has personal loan? (categorical: 'no','yes','unknown')\n",
    "# related with the last contact of the current campaign:\n",
    "8 - contact: contact communication type (categorical: 'cellular','telephone')\n",
    "9 - month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
    "10 - day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\n",
    "11 - duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
    "# other attributes:\n",
    "12 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
    "13 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n",
    "14 - previous: number of contacts performed before this campaign and for this client (numeric)\n",
    "15 - poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n",
    "# social and economic context attributes\n",
    "16 - emp.var.rate: employment variation rate - quarterly indicator (numeric)\n",
    "17 - cons.price.idx: consumer price index - monthly indicator (numeric)\n",
    "18 - cons.conf.idx: consumer confidence index - monthly indicator (numeric)\n",
    "19 - euribor3m: euribor 3 month rate - daily indicator (numeric)\n",
    "20 - nr.employed: number of employees - quarterly indicator (numeric)\n",
    "\n",
    "Output variable (desired target):\n",
    "21 - y - has the client subscribed a term deposit? (binary: 'yes','no')\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4: Understanding the Task\n",
    "\n",
    "After examining the description and data, your goal now is to clearly state the *Business Objective* of the task.  State the objective below."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Understanding\n",
    "From a business perspective, we are tasked to compare the classifiers, K-Nearest Neighbors, Logistic Regression, Decision Trees, and Support Vector Machines to predict the outcome of a bank promotions campaign against individuals.\n",
    "1. Determine Business Objectives\n",
    "    * Background: The  dataset [../data/bank-additional-full.csv) contains Portugese banking institution and is a collection of the results of multiple marketing campaigns.\n",
    "\n",
    "    * Business Objectives:  The goal is to build a predictive model that can label a data item into one of several predefined classes (e.g. “yes”, “no”) using various classification data minning approaches. \n",
    "\n",
    "    * Business Success Criteria: Provide a report on explored classification, models and anlysis of results to determine if the client subscribed a term deposit\n",
    "\n",
    "\n",
    "2. Assess the Situation\n",
    "    * Inventory of Resources: Assignment files \"practical-application-3\" containing starter Jupiter notebook, three dataset [dataset](../data),  accompanying article CRISP-DM-BANK.pdf for more information on the data and features and how the campaign were carried out\n",
    "    * Requirements, Assumptions, and Constraints: Provide a report on explored classification, models and anlysis . The assumption is that as the dataset is from the public database  UCI Machine Learning repository it's acceptable to use it in a practical assignment. \n",
    "\n",
    "    * Risks and Contingencies terminology: The success will depend on my understanding of topics covered up to module 17, the data processing is done on the dataset, and the modal/modals I selected as a part of my solution.\n",
    "\n",
    "    * Costs and Benefits: The derived modal will help my client, to access the classifier performance, classification metrics, such as accuracy rate or ROC curve, Lift curve.\n",
    "\n",
    "3. Determine Data Mining Goals\n",
    "    * Data Mining Goals： shows the predictive results for the test data during the three CRISP-DM iterations of classification models\n",
    "\n",
    "    * Data Mining Success Criteria： Build a predictive model that can label a data item into one of several predefined classes (e.g. “yes”, “no”). Several DM algorithms can be used for classifying marketing contacts, each one with its own purposes and capabilities\n",
    "4. Produce Project Plan\n",
    "    * Project Plan： CRISP-DM is used in the project as a cyclic process, where several iterations can be used to allow final result more tuned towards the business goals.\n",
    "    * Initial Assessment of Tools and Techniques： Jupiter Notebook is used as a computational documents tool for this assignment. The programming language used is Python, and the libraries used are: Pandas, Plotly, Seaborn, Matplotlib,  Numpy , Sklearn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Understanding\n",
    "\n",
    "After considering the business understanding, I explored dataset to understand the data columns and data contained in each column and identify any quality issues. \n",
    "Data Understanding\n",
    "\n",
    "##### Collect Initial Data\n",
    "The data represents 17 marketing campaigns occured between May 2008 and Nov 2010, corresponding to a total of 79354 contacts.\n",
    "\n",
    "##### Describe Data\n",
    "Data Description report: \n",
    "* There are 5 int64 columns,5  float64 columns, and 10 object columns. \n",
    "* The bank-additional.csv'.csv dataset contains following attributes:\n",
    "Attribute Information:\n",
    "Input variables:\n",
    "\n",
    "bank client data: \n",
    "* age (numeric)\n",
    "* job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n",
    "* marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n",
    "* education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n",
    "* default: has credit in default? (categorical: 'no','yes','unknown')\n",
    "*  housing: has housing loan? (categorical: 'no','yes','unknown')\n",
    "*  loan: has personal loan? (categorical: 'no','yes','unknown')\n",
    "\n",
    "related with the last contact of the current campaign:\n",
    "* contact: contact communication type (categorical: 'cellular','telephone')\n",
    "* month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
    "*  day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\n",
    "*  duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
    "\n",
    "other attributes:\n",
    "*  campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
    "* pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n",
    "*  previous: number of contacts performed before this campaign and for this client (numeric)\n",
    "*  poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n",
    "\n",
    "social and economic context attributes\n",
    "* emp.var.rate: employment variation rate - quarterly indicator (numeric)\n",
    "* cons.price.idx: consumer price index - monthly indicator (numeric)\n",
    "* cons.conf.idx: consumer confidence index - monthly indicator (numeric)\n",
    "* euribor3m: euribor 3 month rate - daily indicator (numeric)\n",
    "* nr.employed: number of employees - quarterly indicator (numeric)\n",
    "\n",
    "\n",
    "\n",
    "Output variable (desired target):\n",
    "*  y - has the client subscribed a term deposit? (binary: 'yes','no')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe data\n",
    "df.info()\n",
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Explore & Verify data \n",
    "The dataset dosen't contain null values\n",
    "1. Check for Null values: No null values found \n",
    "2. Determine the unique values for each columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe data\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe data\n",
    "df.describe(include = ['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe data\n",
    "df.describe().astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explore and verify data\n",
    "# Checking for nulls\n",
    "df.isnull().sum(axis = 1)\n",
    "#Result N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explore and Verify unique data in column\n",
    "df_unique = df.nunique().to_frame().reset_index()\n",
    "df_unique.columns = ['Variable','DistinctCount']\n",
    "print(df_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explore and verify data\n",
    "#Print unique values for each column¶\n",
    "category_features = df.select_dtypes(include=['object', 'bool']).columns.values\n",
    "\n",
    "for col in category_features:\n",
    "    print(col, \"(\", len(df[col].unique()) , \"values):\\n\", np.sort(df[col].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explore and verify data\n",
    "for col in category_features:\n",
    "    print(f\"\\033[1m\\033[94m{col} \\n{20 * '-'}\\033[0m\")    \n",
    "    print(df[col].value_counts(), \"\\n\")\n",
    "    \n",
    "print(df.nunique(axis=1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Visulization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Describe data and visualize it\n",
    "df.corr()\n",
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(df.corr(), annot=True)\n",
    "plt.title('Correlation between the features ')\n",
    "plt.savefig(\"images/feature_corr\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Describe data and visualize it\n",
    " #visualize distributions of numerical features with histograms\n",
    " df[['age','duration','campaign','previous']].hist(bins=30, figsize=(20,15))\n",
    "plt.savefig(\"images/attribute_histogram_plots\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize categorical features of the dataset\n",
    "for col in category_features:\n",
    "    plt.figure(figsize=(10,5))    \n",
    "    sns.barplot(df[col].value_counts().values, df[col].value_counts().index, data=df)    \n",
    "    plt.title(col)    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"images/\"+col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#Scatter matrix and Correlation matrix¶\n",
    "\n",
    "sc_matrix = pd.plotting.scatter_matrix(df[['age','duration','campaign']],figsize=(10,8),color=\"pink\")\n",
    "\n",
    "plt.suptitle('The Scatter Matrix of Age, Duration and Campaign')\n",
    "plt.savefig(\"images/age_dur_camp\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference:\n",
    "\n",
    "* Job: Administrators, blue-collars, and technicians are mostly targeted by the campaigns.\n",
    "* Marital status: The campaigns target mostly married people as they are more likely to do term deposit.\n",
    "* Education: Education play a key role, more the education its more likley the client will do term deposits\n",
    "* default/credit: Most people have no default stay on their credit file.\n",
    "* housing an loan: People who own house and has loan are less likely to go for term deposits\n",
    "* contact: Best way to reach clinet is cellular .\n",
    "* month - May is the busy month reason could be due to sunny wether. December is the least busy month, because of the holidays season.\n",
    "* day of week: Thursday is the most busy day while Friday is the least busy day of the week as client are getting ready for the weekend hence don't want to consider term deposit."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "After my initial exploration and fine tuning of the business understanding, it is time to construct my final dataset prior to modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Change column name: 'y' to 'response'\n",
    "df.rename(index=str, columns={'y': 'response'}, inplace = True)\n",
    "def convert(df1, new_column, old_column):\n",
    "    df1[new_column] = df1[old_column].apply(lambda x: 0 if x == 'no' else 1)\n",
    "    return df[new_column].value_counts()\n",
    "\n",
    "convert(df, \"response_binary\", \"response\")\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Data Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop column \"contact\" as its not usefull\n",
    "df1 = df.drop('contact', axis=1)\n",
    "#Change the unit of 'duration' from seconds to minutes\n",
    "df1['duration'] = df1['duration'].apply(lambda n:n/60).round(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop rows that 'duration' < 5s\n",
    "duration_condition = (df1['duration']<5/60)\n",
    "df2 = df1.drop(df1[duration_condition].index, axis = 0, inplace = False)\n",
    "df2.shape\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the relationship between 'duration' & 'campaign': with response result\n",
    "duration_distance_plot_res = sns.lmplot(x='duration', y='campaign',data = df2,\n",
    "                     hue = 'response',\n",
    "                     fit_reg = False,\n",
    "                     scatter_kws={'alpha':0.8,}, height =7)\n",
    "\n",
    "plt.axis([0,65,0,65])\n",
    "plt.ylabel('Number of Calls')\n",
    "plt.xlabel('Duration of Calls (Minutes)')\n",
    "plt.title('The Relationship between the Number and Duration of Calls (with Response Result)')\n",
    "\n",
    "# Annotation\n",
    "plt.axhline(y=5, linewidth=2, color=\"brown\", linestyle='--')\n",
    "plt.annotate('Higher subscription rate when calls <5',xytext = (35,13),\n",
    "             arrowprops=dict(color = 'blue', width=1),xy=(30,6))\n",
    "plt.savefig(\"images/call_duration\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize of data for subscription to term deposit\n",
    "labels = [\"Not \\nsubscribed\", \"Subscribed\"]\n",
    "explode = (0, 0.1)  # only \"explode\" the second slice (i.e. 'Subscribed')\n",
    "\n",
    "# depicting the visualization \n",
    "fig = plt.figure() \n",
    "ax = fig.add_axes([0,0,1,1]) \n",
    "\n",
    "ax.pie(df2['response'].value_counts(), \n",
    "       labels = labels,\n",
    "       explode = explode,\n",
    "       autopct ='%1.2f%%',\n",
    "       frame = True,\n",
    "       textprops = dict(color =\"black\", size=12)) \n",
    "\n",
    "ax.axis('equal') \n",
    "plt.title('Subcription to the term deposit\\n% of Total Clients',\n",
    "     loc='left',\n",
    "     color = 'black', \n",
    "     fontsize = '18')\n",
    "plt.savefig(\"images/piechart\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the target audience and identify customers which were more likely to subscribe to the term deposit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.crosstab(df2['job'], df2['response_binary'])\n",
    "table = round(table.div(table.sum(axis=1), axis=0).mul(100), 2)\n",
    "table.columns=['notsubcribed', 'subcribed']\n",
    "table.sort_values(by=['subcribed'], ascending=False).loc[:, 'subcribed']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "table = pd.crosstab(df2['job'], df2['response'])\n",
    "table.columns = ['Not subscribed', 'Subscribed']\n",
    "table.plot(kind='bar')\n",
    "\n",
    "plt.grid(True)\n",
    "\n",
    "plt.title('Purchase Frequency for Job Title')\n",
    "plt.xlabel('Job')\n",
    "plt.ylabel('Frequency of Purchase')\n",
    "plt.savefig(\"images/purchase_vs_job\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,6))\n",
    "plt.subplot(1,2,1)\n",
    "sns.barplot(x='month',y='duration' , data=df2)\n",
    "plt.subplot(1,2,2)\n",
    "sns.barplot(x='month',y='duration', hue='response', data=df2)\n",
    "plt.savefig(\"images/month\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inferece\n",
    "Longer calls were need during sping, fall and during decemner indicating Holiday period were customer is more unlikly to do term deposit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,6))\n",
    "plt.subplot(1,2,1)\n",
    "sns.barplot(x='month',y='campaign' , data=df2)\n",
    "plt.subplot(1,2,2)\n",
    "sns.barplot(x='month',y='campaign', hue='response', data=df2)\n",
    "plt.savefig(\"images/month_camp\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference\n",
    "The campaign was more effective during summer months and dipped during other spring and fall holidays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5: Engineering Features\n",
    "\n",
    "Now that you understand your business objective, we will build a basic model to get started.  Before we can do this, we must work to encode the data.  Using just the bank information features (columns 1 - 7), prepare the features and target column for modeling with appropriate encoding and transformations."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Transformations and Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['marital','default', 'housing', 'loan', 'poutcome','job','education','month','response','day_of_week']\n",
    "#\n",
    "# Encode labels of multiple columns at once\n",
    "#\n",
    "df2[cols] = df2[cols].apply(LabelEncoder().fit_transform)\n",
    "#\n",
    "# Print head\n",
    "#\n",
    "df2.head()\n",
    "\n",
    "data=df2\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['age', 'job', 'marital', 'education', 'default', 'housing', 'loan', 'duration','campaign', 'previous', 'poutcome']\n",
    "X = data[selected_features]\n",
    "y = data['response_binary']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6: Train/Test Split\n",
    "\n",
    "With your data prepared, split it into a train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 22)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, stratify = y, random_state=22)\n",
    "print(\"Number transactions X_train dataset: \", X_train.shape)\n",
    "print(\"Number transactions y_train dataset: \", y_train.shape)\n",
    "print(\"Number transactions X_test dataset: \", X_test.shape)\n",
    "print(\"Number transactions y_test dataset: \", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 7: A Baseline Model\n",
    "\n",
    "Before we build our first model, we want to establish a baseline.  What is the baseline performance that our classifier should aim to beat?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using dummy classifier as Baseline model as it's  a type of classifier which does not generate any insight about the data and classifies the given data using only simple rules. The classifier’s behavior is completely independent of the training data as the trends in the training data are completely ignored and instead uses one of the strategies to predict the class label.\n",
    "Below are a few strategies used by the dummy classifier to predict a class label –\n",
    "* Most Frequent: The classifier always predicts the most frequent class label in the training data.\n",
    "* Stratified: It generates predictions by respecting the class distribution of the training data. It is different from the “most frequent” strategy as it instead associates a probability with each data point of being the most frequent class label.\n",
    "* Uniform: It generates predictions uniformly at random.\n",
    "* Constant: The classifier always predicts a constant label and is primarily used when classifying non-majority class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a dummy classifier that always predicts the majority class\n",
    "strategies = ['most_frequent', 'stratified', 'uniform']\n",
    "  \n",
    "test_scores = []\n",
    "for s in strategies:\n",
    "    \n",
    "    dummy = DummyClassifier(strategy = s)\n",
    "  \n",
    "    # Fit the classifier on the training data\n",
    "    dummy.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the classifier on the test data\n",
    "    accuracy = dummy.score(X_test, y_test)\n",
    "    print(\"Strategies\",s)\n",
    "    # Print the baseline accuracy\n",
    "    print(\"Baseline accuracy: {:.2f}\".format(accuracy))\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 8: A Simple Model\n",
    "\n",
    "Use Logistic Regression to build a basic model on your data.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the storage dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['Name', 'Train Time', 'Train Accuracy', 'Test Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Define the search space for Logistic Regression\n",
    "log_reg_params = {'solver': ['liblinear', 'lbfgs'], 'penalty': ['l1', 'l2'], 'C': [0.1, 1, 10, 100], 'class_weight': [None, 'balanced']}\n",
    "log_reg_model=\"\"\n",
    "# Grid search for Logistic Regression\n",
    "log_reg_model = GridSearchCV(LogisticRegression(), log_reg_params, cv=5)\n",
    "log_reg_model.fit(X_train, y_train)\n",
    "\n",
    "log_reg_best_params = log_reg_model.best_params_\n",
    "\n",
    "\n",
    "# Evaluate the logistic regression model on the train data\n",
    "train_accuracy = log_reg_model.score(X_train, y_train)\n",
    "test_accuracy = log_reg_model.score(X_test, y_test)\n",
    "# Print the train  accuracy\n",
    "print(\"Train accuracy: {:.2f}\".format(train_accuracy))\n",
    "\n",
    "print(\"Test accuracy: {:.2f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Selected parameters assignement\n",
    "log_reg_params = {'C': 0.1, 'class_weight': None, 'penalty': 'l1', 'solver': 'liblinear'}\n",
    "start_time = time.time()\n",
    "log_reg_model= LogisticRegression(**log_reg_params)\n",
    "log_reg_model.fit(X_train,y_train)\n",
    "end_time = time.time()\n",
    "train_time = end_time - start_time\n",
    "# Evaluate the logistic regression model on the train data\n",
    "train_accuracy = log_reg_model.score(X_train, y_train)\n",
    "test_accuracy = log_reg_model.score(X_test, y_test)\n",
    "\n",
    "log_reg_model_result = pd.DataFrame({'Name': ['Logistic Regression'], 'Train Time': [train_time], 'Train Accuracy': [train_accuracy], 'Test Accuracy': [test_accuracy]})\n",
    "results_df = pd.concat([results_df, log_reg_model_result], ,join_axes=[results_df.columns]))\n",
    "# Print the train  accuracy\n",
    "print(\"Train accuracy: {:.2f}\".format(train_accuracy))\n",
    "print(\"Test accuracy: {:.2f}\".format(test_accuracy))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference: Evem with different LogisticRegression parameter I got same accuracy of 0.90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 9: Score the Model\n",
    "\n",
    "What is the accuracy of your model?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the logistic regression model on the test data for solver='sag',max_iter=10000\n",
    "accuracy = log_reg_model.score(X_test, y_test)\n",
    "\n",
    "# Print the test accuracy\n",
    "print(\"Test accuracy: {:.2f}\".format(accuracy))\n",
    "\n",
    "\n",
    "# Evaluate the logistic regression model on the test data solver='liblinear'\n",
    "accuracy = log_reg_model.score(X_test, y_test)\n",
    "\n",
    "# Print the test accuracy\n",
    "print(\"Test accuracy: {:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data for LogRegModel\n",
    "y_pred = log_reg_model.predict(X_test)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Create a confusion matrix display\n",
    "cmd = ConfusionMatrixDisplay(cm, display_labels=log_reg_model.classes_)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "cmd.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "y_pred = log_reg_model.predict(X_test)\n",
    "\n",
    "\n",
    "# Calculate the precision, recall, and F1 score\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "# Print the performance metrics\n",
    "print(\"Precision: {:.3f}\".format(precision))\n",
    "print(\"Recall: {:.3f}\".format(recall))\n",
    "print(\"F1 Score: {:.3f}\".format(f1))\n",
    "\n",
    "# Print the test accuracy\n",
    "print(\"Test accuracy: {:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUC ROC curve  for LogRegModel\n",
    "logit_roc_auc = roc_auc_score(y_test,y_pred)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, log_reg_model.predict_proba(X_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve Logistic Regression')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('images/Log_ROC_Logistic Regression')\n",
    "plt.show()\n",
    "auc_score =roc_auc_score(y_test, log_reg_model.predict_proba(X_test)[:,1])\n",
    "print(\"Logistic Regression AUC Score: {:.2f}\".format(auc_score))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 10: Model Comparisons\n",
    "\n",
    "Now, we aim to compare the performance of the Logistic Regression model to our KNN algorithm, Decision Tree, and SVM models.  Using the default settings for each of the models, fit and score each.  Also, be sure to compare the fit time of each of the models.  Present your findings in a `DataFrame` similar to that below:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare configuration for cross validation test harness\n",
    "seed = 7\n",
    "cv_results =[]\n",
    "# prepare models\n",
    "models = []\n",
    "# Model parameters\n",
    "log_reg_params = {'solver': 'liblinear', 'C': 1.0, 'penalty': 'l2', 'class_weight': 'balanced'}\n",
    "dec_tree_params = {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1}\n",
    "knn_params = {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 30}\n",
    "svm_params = {'C': 1.0, 'kernel': 'rbf', 'degree': 3, 'gamma': 'scale', 'class_weight': 'balanced'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Fit the LogisticRegression models\n",
    "log_reg = LogisticRegression(**log_reg_params)\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred =log_reg.predict(X_test)\n",
    "# computing and plotting confusion matrix\n",
    "c_m = confusion_matrix(y_test, y_pred)\n",
    "print('LogisticRegression:\\n confusion matrix\\n', c_m,'\\n\\n')\n",
    "models.append(('LogisticRegression',log_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Fit the DecisionTreeClassifier models\n",
    "dec_tree = DecisionTreeClassifier(**dec_tree_params)\n",
    "dec_tree.fit(X_train, y_train)\n",
    "y_pred =dec_tree.predict(X_test)\n",
    "# computing and plotting confusion matrix\n",
    "c_m = confusion_matrix(y_test, y_pred)\n",
    "print('DecisionTreeClassifier:\\n confusion matrix\\n', c_m,'\\n\\n')\n",
    "models.append(('DecisionTreeClassifier',dec_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Fit the KNeighborsClassifier models\n",
    "knn = KNeighborsClassifier(**knn_params)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred =knn.predict(X_test)\n",
    "# computing and plotting confusion matrix\n",
    "c_m = confusion_matrix(y_test, y_pred)\n",
    "print('KNeighborsClassifier:\\n confusion matrix\\n', c_m,'\\n\\n')\n",
    "models.append(('KNeighborsClassifier',knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Fit the SVC models\n",
    "svm = SVC(**svm_params)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred =svm.predict(X_test)\n",
    "# computing and plotting confusion matrix\n",
    "c_m = confusion_matrix(y_test, y_pred)\n",
    "print('SVC:\\n confusion matrix\\n', c_m,'\\n\\n')\n",
    "models.append(('SVC',svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\training\\ML-AI\\Module17\\BH-PCMLAI-Module17-PracticalApplication-3\\notebook\\practical-assignment-3.ipynb Cell 73\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/training/ML-AI/Module17/BH-PCMLAI-Module17-PracticalApplication-3/notebook/practical-assignment-3.ipynb#Y266sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m kfold\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/training/ML-AI/Module17/BH-PCMLAI-Module17-PracticalApplication-3/notebook/practical-assignment-3.ipynb#Y266sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m name, model \u001b[39min\u001b[39;00m models:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/training/ML-AI/Module17/BH-PCMLAI-Module17-PracticalApplication-3/notebook/practical-assignment-3.ipynb#Y266sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     cv_results \u001b[39m=\u001b[39m cross_val_score(model, X, y, cv\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, scoring\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39maccuracy\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/training/ML-AI/Module17/BH-PCMLAI-Module17-PracticalApplication-3/notebook/practical-assignment-3.ipynb#Y266sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     results\u001b[39m.\u001b[39mappend(cv_results)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/training/ML-AI/Module17/BH-PCMLAI-Module17-PracticalApplication-3/notebook/practical-assignment-3.ipynb#Y266sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     names\u001b[39m.\u001b[39mappend(name)\n",
      "File \u001b[1;32mc:\\Users\\peshne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    513\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[1;32m--> 515\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[0;32m    516\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m    517\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    518\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    519\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[0;32m    520\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[0;32m    521\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[0;32m    522\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    523\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    524\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[0;32m    525\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[0;32m    526\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    527\u001b[0m )\n\u001b[0;32m    528\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\peshne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    265\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 266\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    268\u001b[0m         clone(estimator),\n\u001b[0;32m    269\u001b[0m         X,\n\u001b[0;32m    270\u001b[0m         y,\n\u001b[0;32m    271\u001b[0m         scorers,\n\u001b[0;32m    272\u001b[0m         train,\n\u001b[0;32m    273\u001b[0m         test,\n\u001b[0;32m    274\u001b[0m         verbose,\n\u001b[0;32m    275\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    276\u001b[0m         fit_params,\n\u001b[0;32m    277\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[0;32m    278\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    279\u001b[0m         return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[0;32m    280\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    281\u001b[0m     )\n\u001b[0;32m    282\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m cv\u001b[39m.\u001b[39;49msplit(X, y, groups)\n\u001b[0;32m    283\u001b[0m )\n\u001b[0;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    287\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\peshne\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\peshne\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\peshne\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\peshne\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\peshne\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\peshne\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\peshne\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\peshne\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\peshne\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\peshne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:708\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    705\u001b[0m result[\u001b[39m\"\u001b[39m\u001b[39mfit_error\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    707\u001b[0m fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n\u001b[1;32m--> 708\u001b[0m test_scores \u001b[39m=\u001b[39m _score(estimator, X_test, y_test, scorer, error_score)\n\u001b[0;32m    709\u001b[0m score_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time \u001b[39m-\u001b[39m fit_time\n\u001b[0;32m    710\u001b[0m \u001b[39mif\u001b[39;00m return_train_score:\n",
      "File \u001b[1;32mc:\\Users\\peshne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:767\u001b[0m, in \u001b[0;36m_score\u001b[1;34m(estimator, X_test, y_test, scorer, error_score)\u001b[0m\n\u001b[0;32m    765\u001b[0m         scores \u001b[39m=\u001b[39m scorer(estimator, X_test)\n\u001b[0;32m    766\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 767\u001b[0m         scores \u001b[39m=\u001b[39m scorer(estimator, X_test, y_test)\n\u001b[0;32m    768\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    769\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(scorer, _MultimetricScorer):\n\u001b[0;32m    770\u001b[0m         \u001b[39m# If `_MultimetricScorer` raises exception, the `error_score`\u001b[39;00m\n\u001b[0;32m    771\u001b[0m         \u001b[39m# parameter is equal to \"raise\".\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\peshne\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py:115\u001b[0m, in \u001b[0;36m_MultimetricScorer.__call__\u001b[1;34m(self, estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    114\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(scorer, _BaseScorer):\n\u001b[1;32m--> 115\u001b[0m         score \u001b[39m=\u001b[39m scorer\u001b[39m.\u001b[39m_score(cached_call, estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    116\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    117\u001b[0m         score \u001b[39m=\u001b[39m scorer(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\peshne\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py:276\u001b[0m, in \u001b[0;36m_PredictScorer._score\u001b[1;34m(self, method_caller, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_score\u001b[39m(\u001b[39mself\u001b[39m, method_caller, estimator, X, y_true, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    249\u001b[0m     \u001b[39m\"\"\"Evaluate predicted target values for X relative to y_true.\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \n\u001b[0;32m    251\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[39m        Score function applied to prediction of estimator on X.\u001b[39;00m\n\u001b[0;32m    274\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 276\u001b[0m     y_pred \u001b[39m=\u001b[39m method_caller(estimator, \u001b[39m\"\u001b[39;49m\u001b[39mpredict\u001b[39;49m\u001b[39m\"\u001b[39;49m, X)\n\u001b[0;32m    277\u001b[0m     \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    278\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sign \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_score_func(\n\u001b[0;32m    279\u001b[0m             y_true, y_pred, sample_weight\u001b[39m=\u001b[39msample_weight, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_kwargs\n\u001b[0;32m    280\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\peshne\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py:73\u001b[0m, in \u001b[0;36m_cached_call\u001b[1;34m(cache, estimator, method, *args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[39m\"\"\"Call estimator with method and args and kwargs.\"\"\"\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[39mif\u001b[39;00m cache \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(estimator, method)(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     75\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m     \u001b[39mreturn\u001b[39;00m cache[method]\n",
      "File \u001b[1;32mc:\\Users\\peshne\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:820\u001b[0m, in \u001b[0;36mBaseSVC.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    818\u001b[0m     y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecision_function(X), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m    819\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 820\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mpredict(X)\n\u001b[0;32m    821\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m.\u001b[39mtake(np\u001b[39m.\u001b[39masarray(y, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mintp))\n",
      "File \u001b[1;32mc:\\Users\\peshne\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:435\u001b[0m, in \u001b[0;36mBaseLibSVM.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    433\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_for_predict(X)\n\u001b[0;32m    434\u001b[0m predict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sparse_predict \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sparse \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dense_predict\n\u001b[1;32m--> 435\u001b[0m \u001b[39mreturn\u001b[39;00m predict(X)\n",
      "File \u001b[1;32mc:\\Users\\peshne\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:454\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    446\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    447\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mX.shape[1] = \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m should be equal to \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    448\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mthe number of samples at training time\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    449\u001b[0m             \u001b[39m%\u001b[39m (X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape_fit_[\u001b[39m0\u001b[39m])\n\u001b[0;32m    450\u001b[0m         )\n\u001b[0;32m    452\u001b[0m svm_type \u001b[39m=\u001b[39m LIBSVM_IMPL\u001b[39m.\u001b[39mindex(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_impl)\n\u001b[1;32m--> 454\u001b[0m \u001b[39mreturn\u001b[39;00m libsvm\u001b[39m.\u001b[39;49mpredict(\n\u001b[0;32m    455\u001b[0m     X,\n\u001b[0;32m    456\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msupport_,\n\u001b[0;32m    457\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msupport_vectors_,\n\u001b[0;32m    458\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_n_support,\n\u001b[0;32m    459\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dual_coef_,\n\u001b[0;32m    460\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_intercept_,\n\u001b[0;32m    461\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_probA,\n\u001b[0;32m    462\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_probB,\n\u001b[0;32m    463\u001b[0m     svm_type\u001b[39m=\u001b[39;49msvm_type,\n\u001b[0;32m    464\u001b[0m     kernel\u001b[39m=\u001b[39;49mkernel,\n\u001b[0;32m    465\u001b[0m     degree\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdegree,\n\u001b[0;32m    466\u001b[0m     coef0\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcoef0,\n\u001b[0;32m    467\u001b[0m     gamma\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_gamma,\n\u001b[0;32m    468\u001b[0m     cache_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcache_size,\n\u001b[0;32m    469\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "kfold=10\n",
    "for name, model in models:\n",
    "    cv_results = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "   \n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "    print(\"%s:\" % cv_results)\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "ax.tick_params(axis='x', labelrotation = 100)\n",
    "plt.savefig(\"algorithmcomparision\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: Decison Tree is the best model for Portuguese bank direct marketing data mining project"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 11: Improving the Model\n",
    "\n",
    "Now that we have some basic models on the board, we want to try to improve these.  Below, we list a few things to explore in this pursuit.\n",
    "\n",
    "- More feature engineering and exploration.  For example, should we keep the gender feature?  Why or why not?\n",
    "- Hyperparameter tuning and grid search.  All of our models have additional hyperparameters to tune and explore.  For example the number of neighbors in KNN or the maximum depth of a Decision Tree.  \n",
    "- Adjust your performance metric"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2nd attempt at comparing Models by tweaking parameter and using othe hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search space for Decision Tree\n",
    "dec_tree_params ={'max_depth': [1,2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "         'min_samples_split': [0.10,0.15,0.20,0.25,0.30,0.35,0.40,0.45,0.50],\n",
    "          'criterion': ['gini', 'entropy'],\n",
    "          'min_samples_leaf': [1,2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "         }\n",
    "\n",
    "# Define the search space for KNN\n",
    "\n",
    "knn_params = {'model__kernel': ['rbf', 'poly', 'linear', 'sigmoid'],'gamma': [0.1, 1.0, 10.0, 100.0]}\n",
    "\n",
    "# Define the search space for SVM\n",
    "\n",
    "svm_params =  {\n",
    "    'model__kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "}\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Grid search for Decision Tree this is model is too slow please uncomment and run to see in action \n",
    "start_time = time.time()\n",
    "#grid_GridSearchCV = GridSearchCV(DecisionTreeClassifier(random_state = 42), param_grid=dec_tree_params).fit(X_train, y_train)\n",
    "#end_time = time.time()\n",
    "#train_time = end_time - start_time\n",
    "#train_accuracy = grid_GridSearchCV.score(X_train, y_train)\n",
    "#test_accuracy = grid_GridSearchCV.score(X_test, y_test)\n",
    "#grid_GridSearchCV_best_params = grid_GridSearchCV.best_params_\n",
    "#print(f'GridSearchCV Training Accuracy: {train_accuracy: .2f}')\n",
    "#print(f'GridSearchCV Test Accuracy: {test_accuracy: .2f}')\n",
    "#print(f'GridSearchCV Best parameters of tree: {grid_GridSearchCV_best_params}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "start_time = time.time()\n",
    "#dec_tree_model = DecisionTreeClassifier(random_state=42)\n",
    "dec_tree_model.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "train_time = end_time - start_time\n",
    "\n",
    "train_accuracy = dec_tree_model.score(X_train, y_train)\n",
    "test_accuracy = dec_tree_model.score(X_test, y_test)\n",
    "print(\"Train accuracy: {:.2f}\".format(train_accuracy))\n",
    "print(\"Test accuracy: {:.2f}\".format(test_accuracy))\n",
    "\n",
    "dec_tree_model_results = pd.DataFrame({'Name': ['Decision Tree'], 'Train Time': [train_time], 'Train Accuracy': [train_accuracy], 'Test Accuracy': [test_accuracy]})\n",
    "results_df = pd.concat([results_df, dec_tree_model_results],join_axes=[results_df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUC ROC curve  for LogRegModel\n",
    "logit_roc_auc = roc_auc_score(y_test,y_pred)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, dec_tree_model.predict_proba(X_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Decision Tree (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve Decision Tree')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('images/Log_ROC_DecisionTree')\n",
    "plt.show()\n",
    "auc_score =roc_auc_score(y_test, dec_tree_model.predict_proba(X_test)[:,1])\n",
    "print(\"Decision Tree  AUC Score: {:.2f}\".format(auc_score))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " %%time\n",
    " from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Fit and time the KNN model\n",
    "\n",
    "start_time = time.time()\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Cross Validation to Get the Best Value of k\n",
    "k_values = [i for i in range (1,31)]\n",
    "scores = []\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    score = cross_val_score(knn, X, y, cv=5)\n",
    "    scores.append(np.mean(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can plot the results with the following code\n",
    "sns.lineplot(x = k_values, y = scores, marker = 'o')\n",
    "plt.xlabel(\"K Values\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.savefig('images/KValues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " %%time\n",
    "#We can now train our model using the best k value using the code below.\n",
    "best_index = np.argmax(scores)\n",
    "best_k = k_values[best_index]\n",
    "start_time = time.time()\n",
    "knn = KNeighborsClassifier(n_neighbors=best_k)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "end_time = time.time()\n",
    "train_time = end_time - start_time\n",
    "train_accuracy = knn.score(X_train, y_train)\n",
    "test_accuracy = knn.score(X_test, y_test)\n",
    "print(\"Train accuracy: {:.2f}\".format(train_accuracy))\n",
    "print(\"Test accuracy: {:.2f}\".format(test_accuracy))\n",
    "knn_results = pd.DataFrame({'Name': ['KNN'], 'Train Time': [train_time], 'Train Accuracy': [train_accuracy], 'Test Accuracy': [test_accuracy]})\n",
    "results_df = pd.concat([results_df, knn_results], ,join_axes=[results_df.columns]))\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfMat=confusion_matrix(y_test, y_pred, labels=[1, 0])\n",
    "print (ConfMat)\n",
    "\n",
    "ConfMat_DF = pd.DataFrame(ConfMat, index = [i for i in [\"1\",\"0\"]],\n",
    "                  columns = [i for i in [\"Predict 1\",\"Predict 0\"]])\n",
    "plt.figure(figsize = (7,4))\n",
    "sns.heatmap(ConfMat_DF, annot=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_roc_auc = roc_auc_score(y_test,y_pred)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, knn.predict_proba(X_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='KNN (area = %0.2f)' % knn_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Knn Model')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('images/Log_ROC_KNN')\n",
    "plt.show()\n",
    "auc_score = roc_auc_score(y_test, knn.predict_proba(X_test)[:,1])\n",
    "print(\"KNN AUC Score:\",auc_score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " %%time\n",
    "# Fit and time the SVM model\n",
    "\n",
    "start_time = time.time()\n",
    "svc=SVC(C= .1, kernel='rbf', gamma= 'auto',probability=True)\n",
    "svc.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "train_time = end_time - start_time\n",
    "y_pred = svc.predict(X_test)\n",
    "train_accuracy = svc.score(X_train, y_train)\n",
    "test_accuracy = svc.score(X_test, y_test)\n",
    "print(\"Train accuracy: {:.2f}\".format(train_accuracy))\n",
    "print(\"Test accuracy: {:.2f}\".format(test_accuracy))\n",
    "svc_results = pd.DataFrame({'Name': ['SVC'], 'Train Time': [train_time], 'Train Accuracy': [train_accuracy], 'Test Accuracy': [test_accuracy]})\n",
    "results_df = pd.concat([results_df, svc_results], ,join_axes=[results_df.columns]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfMat=confusion_matrix(y_test, y_pred, labels=[1, 0])\n",
    "print (ConfMat)\n",
    "\n",
    "ConfMat_DF = pd.DataFrame(ConfMat, index = [i for i in [\"1\",\"0\"]],\n",
    "                  columns = [i for i in [\"Predict 1\",\"Predict 0\"]])\n",
    "plt.figure(figsize = (7,4))\n",
    "sns.heatmap(ConfMat_DF, annot=True, cmap='GnBu',center=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_roc_auc = roc_auc_score(y_test,y_pred)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, svc.predict_proba(X_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='SVC (area = %0.2f)' % svc_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for SVC Model')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('KNN_ROC')\n",
    "plt.show()\n",
    "auc_score = roc_auc_score(y_test, svc.predict_proba(X_test)[:,1])\n",
    "print(\"KNN AUC Score:\",auc_score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Result Comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the index to be the 'Name' column\n",
    "results_df.set_index('Name', inplace=True)\n",
    "\n",
    "# Set bar width and positions\n",
    "bar_width = 0.35\n",
    "bar_positions = np.arange(len(results_df))\n",
    "\n",
    "# Create the side-by-side bar plots for Train Accuracy and Test Accuracy\n",
    "ax = results_df['Train Accuracy'].plot(kind='bar', width=bar_width, position=1, label='Train Accuracy')\n",
    "results_df['Test Accuracy'].plot(kind='bar', width=bar_width, position=0, color='orange', label='Test Accuracy', ax=ax)\n",
    "\n",
    "# Set labels\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "# Set x-axis ticks and labels\n",
    "plt.xticks(bar_positions, results_df.index, rotation=45)\n",
    "\n",
    "# Add title\n",
    "plt.title('Model Performance Comparison')\n",
    "\n",
    "# Display the 'Train Time' as a number on top of the 'Train Accuracy' bar\n",
    "for idx, value in enumerate(results_df['Train Time']):\n",
    "    ax.text(idx - 0.15, results_df['Train Accuracy'][idx] + 0.01, f'{value:.2f}s', fontsize=9)\n",
    "\n",
    "# Display the legend outside the plot area\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the 'Name' column back to results_df as a categorical column\n",
    "\n",
    "# Create a scatter plot matrix with model names as colors\n",
    "sns.pairplot(results_df[['Name','index','Train Time','Train Accuracy','Test Accuracy']], hue='Name', diag_kind='hist', markers='D', corner=True, plot_kws=dict(s=50, edgecolor=\"w\", linewidth=1))\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concusion: Decison Tree is the best model for Portuguese bank direct marketing data mining project followed by Logistic Regression.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Questions\n",
    "It would be worth while to try other model I learnt in this course, due to lack of time I couldn't explore it. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
